[settings]
learning_rate = 0.0001
batch_size = 64
iterations = 10

[[layer]]
type = "dense"
dim_in = 784
dim_out = 264
activation = "relu"

[[layer]]
type = "vanillalowrank"
dim_in = 264
dim_out = 264
activation = "relu"
rank = 30


[[layer]]
type = "dense"
dim_in = 264
dim_out = 10
activation = "linear"